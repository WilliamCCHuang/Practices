{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一篇文章教你用 11 行 Python 代碼實現神經網絡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出的爲樣本爲 X 爲 4×3，有 4 個樣本 3 個屬性，每一個樣本對於這一個真實值 y，爲 4×1 的向量，我們要根據 input 的值輸出與 y 值損失最小的輸出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "$$\n",
    "    X = \\begin{bmatrix}\n",
    "        0 & 0 & 1 \\\\\n",
    "        1 & 1 & 1 \\\\\n",
    "        1 & 0 & 1 \\\\\n",
    "        0 & 1 & 1\n",
    "    \\end{bmatrix},\n",
    "    \\;\\;\\;\\;\n",
    "    y = \\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        1 \\\\\n",
    "        1 \\\\\n",
    "        0\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先考慮最簡單的神經網絡，其中第一層是輸入層，第二層是輸出層。輸入層有3個神經元(因爲有3個屬性),輸出爲一個值，w1, w2, w3 爲其權重。輸出爲:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "$$\n",
    "    f(w_1 \\cdot x_1+w_2 \\cdot x_2+w_3 \\cdot x_3)\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡的 f 爲 sigmoid 函數： "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "$$\n",
    "    f(x)=\\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其導數為："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "$$\n",
    "    \\frac{df}{dx}=f(x)(1-f(x))\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神經網絡的優化過程是：\n",
    "1. 前向傳播求損失\n",
    "2. 反向傳播更新 w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式碼如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "\n",
    "# deriv=ture 是求導數\n",
    "\n",
    "def sigmoid(x,deriv=False):\n",
    "\n",
    "    if(deriv==True):\n",
    "\n",
    "        return x*(1-x)\n",
    "\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ReLu function\n",
    "\n",
    "# derive=true 是求導數\n",
    "\n",
    "def relu(x,deriv=False):\n",
    "    \n",
    "    result = np.array([[0.0,0.0,0.0,0.0]]).T\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        if (deriv==False):\n",
    "            \n",
    "            if x[i] >= 0:\n",
    "                \n",
    "                result[i] = x[i]\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            if x[i] >= 0:\n",
    "                \n",
    "                result[i] = 1.0\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_2_layers(X,y,function):\n",
    "\n",
    "    # seed random numbers to make calculation\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # initialize weights randomly with mean 0\n",
    "\n",
    "    syn0 = 2*np.random.random((3,1)) - 1\n",
    "    print(\"syn0=\")\n",
    "    print(syn0)\n",
    "\n",
    "    n = 10000\n",
    "\n",
    "    for iter in range(n):\n",
    "\n",
    "        # forward propagation\n",
    "\n",
    "        # l0也就是輸入層\n",
    "\n",
    "        l0 = X\n",
    "\n",
    "        l1 = function(np.dot(l0,syn0))\n",
    "\n",
    "        # how much did we miss?\n",
    "\n",
    "        l1_error = l1 - y\n",
    "\n",
    "        # multiply how much we missed by the slope of the sigmoid at the values in l1\n",
    "\n",
    "        l1_delta = - l1_error * function(l1,True)\n",
    "\n",
    "        # update weights\n",
    "\n",
    "        syn0 += np.dot(l0.T,l1_delta)\n",
    "\n",
    "    print(\"Output After Training:\")\n",
    "    print(\"syn0=\")\n",
    "    print(syn0)\n",
    "    print(\"l1=\")\n",
    "    print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=\n",
      "[[0 0 1]\n",
      " [1 1 1]\n",
      " [1 0 1]\n",
      " [0 1 1]]\n",
      "y=\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# input dataset\n",
    "\n",
    "X = np.array([  [0,0,1],\n",
    "\n",
    "                [1,1,1],\n",
    "\n",
    "                [1,0,1],\n",
    "\n",
    "                [0,1,1] ])\n",
    "\n",
    "# output dataset            \n",
    "\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "print(\"X=\")\n",
    "print(X)\n",
    "print(\"y=\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn0=\n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "Output After Training:\n",
      "syn0=\n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n",
      "l1=\n",
      "[[ 0.00966449]\n",
      " [ 0.99211957]\n",
      " [ 0.99358898]\n",
      " [ 0.00786506]]\n"
     ]
    }
   ],
   "source": [
    "train_by_2_layers(X,y,sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn0=\n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "Output After Training:\n",
      "syn0=\n",
      "[[-0.11407714]\n",
      " [-1.93882287]\n",
      " [-5.39385291]]\n",
      "l1=\n",
      "[[ 0.        ]\n",
      " [ 3.28455359]\n",
      " [ 2.93882287]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_by_2_layers(X,y,relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們知道，兩層的神經網絡即爲一個小的感知機，它只能出來線性可分的數據，如果是線性不可分，則其出來的效果較差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=\n",
      "[[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n",
      "y=\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# input dataset\n",
    "\n",
    "X = np.array([  [0,0,1],\n",
    "\n",
    "                [0,1,1],\n",
    "\n",
    "                [1,0,1],\n",
    "\n",
    "                [1,1,1] ])\n",
    "\n",
    "# output dataset            \n",
    "\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "print(\"X=\")\n",
    "print(X)\n",
    "print(\"y=\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn0=\n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "Output After Training:\n",
      "syn0=\n",
      "[[  2.08166817e-16]\n",
      " [  2.22044605e-16]\n",
      " [ -3.05311332e-16]]\n",
      "l1=\n",
      "[[ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "train_by_2_layers(X,y,sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn0=\n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "Output After Training:\n",
      "syn0=\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 2.]]\n",
      "l1=\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_by_2_layers(X,y,relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因爲數據並不是線性可分的，因此它是一個非線性的問題，神經網絡的強大之處就是其可以搭建更多的層來對非線性的問題進行處理。下面我將搭建一個含有 5 個神經元的隱含層，要搞清楚 w 的維度：第一層到第二層的 w 爲 3×5，第二層到第三層的 W 爲 5×1，因此還是同樣的兩個步驟，前向計算誤差，然後反向求導更新 w。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式碼如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0,1],\n",
    "\n",
    "            [0,1,1],\n",
    "\n",
    "            [1,0,1],\n",
    "\n",
    "            [1,1,1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "\n",
    "            [1],\n",
    "\n",
    "            [1],\n",
    "\n",
    "            [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_3_layers(X,y,function):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    # randomly initialize our weights with mean 0\n",
    "\n",
    "    syn0 = 2*np.random.random((3,5)) - 1\n",
    "\n",
    "    syn1 = 2*np.random.random((5,1)) - 1\n",
    "\n",
    "    for j in range(60000):\n",
    "\n",
    "        # Feed forward through layers 0, 1, and 2\n",
    "\n",
    "        l0 = X\n",
    "\n",
    "        l1 = function(np.dot(l0,syn0))\n",
    "\n",
    "        l2 = function(np.dot(l1,syn1))\n",
    "\n",
    "        # how much did we miss the target value?\n",
    "\n",
    "        l2_error = y - l2\n",
    "\n",
    "        if (j % 10000) == 0:\n",
    "\n",
    "            print(\"Error:\" + str(np.mean(np.abs(l2_error))))\n",
    "\n",
    "        # in what direction is the target value?\n",
    "\n",
    "        # were we really sure? if so, don't change too much.\n",
    "\n",
    "        l2_delta = l2_error * function(l2,deriv=True)\n",
    "\n",
    "        # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "\n",
    "        l1_error = l2_delta.dot(syn1.T)\n",
    "\n",
    "        # in what direction is the target l1?\n",
    "\n",
    "        # were we really sure? if so, don't change too much.\n",
    "\n",
    "        l1_delta = l1_error * function(l1,deriv=True)\n",
    "\n",
    "        syn1 += l1.T.dot(l2_delta)\n",
    "\n",
    "        syn0 += l0.T.dot(l1_delta)\n",
    "\n",
    "    print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.500628229093\n",
      "Error:0.00899024507125\n",
      "Error:0.0060486255435\n",
      "Error:0.00482794013965\n",
      "Error:0.00412270116481\n",
      "Error:0.00365084766242\n",
      "[[ 0.00225305]\n",
      " [ 0.99723356]\n",
      " [ 0.99635205]\n",
      " [ 0.00456238]]\n"
     ]
    }
   ],
   "source": [
    "train_by_3_layers(X,y,sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
